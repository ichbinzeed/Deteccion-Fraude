# üí≥ Detecci√≥n de Fraudes en Transacciones Financieras con Keras y SMOTE üß†

## üöÄ Descripci√≥n General del Proyecto

Este proyecto se enfoca en la construcci√≥n y evaluaci√≥n de un modelo de **aprendizaje profundo (Deep Learning)** utilizando **Keras** y **TensorFlow** para identificar transacciones financieras fraudulentas. Se aborda el desaf√≠o del **alto desbalance de clases** en el dataset mediante la t√©cnica de sobremuestreo **SMOTE** (Synthetic Minority Over-sampling Technique) y se analizan sus efectos en diversas m√©tricas de evaluaci√≥n.

## üéØ El Problema

El fraude en transacciones con tarjetas de cr√©dito es un problema cr√≠tico que causa p√©rdidas significativas. Los principales desaf√≠os son:
1.  Identificar con alta precisi√≥n las transacciones fraudulentas, que son eventos infrecuentes.
2.  Minimizar los falsos positivos para no incomodar a los clientes con transacciones leg√≠timas bloqueadas.
3.  Manejar eficazmente el **fuerte desbalance de clases** presente en los datos.

## üìä Dataset Utilizado

Se utiliz√≥ el conocido dataset `creditcard.csv`, un est√°ndar para este tipo de problemas:
*   Transacciones de tarjetas de cr√©dito europeas de septiembre de 2013.
*   **Desbalance extremo:** Solo el **0.173%** de las transacciones son fraudulentas.
*   Caracter√≠sticas `V1` a `V28` anonimizadas mediante PCA.
*   Caracter√≠sticas originales: `Time` (descartada) y `Amount`.
*   Variable objetivo `Class`: `1` para fraude, `0` para leg√≠tima.

## ‚öôÔ∏è Metodolog√≠a y Flujo de Trabajo

El proyecto se desarroll√≥ siguiendo estos pasos:

1.  **Carga y Exploraci√≥n Inicial (EDA):**
    *   Importaci√≥n de librer√≠as (TensorFlow, Keras, Pandas, Matplotlib, Seaborn, Scikit-learn, Imbalanced-learn).
    *   Carga del dataset y visualizaci√≥n de la distribuci√≥n de clases.

2.  **Preprocesamiento de Datos:**
    *   Eliminaci√≥n de la columna `Time`.
    *   Separaci√≥n de caracter√≠sticas (`X`) y variable objetivo (`y`).
    *   Divisi√≥n en conjuntos de **entrenamiento (80%)** y **prueba (20%)**.
    *   **Escalado de caracter√≠sticas** con `StandardScaler` en los conjuntos de entrenamiento y prueba.

3.  **Modelo Inicial (Sin Manejo de Desbalance Expl√≠cito):**
    *   Se construy√≥, entren√≥ y evalu√≥ un primer modelo de red neuronal para establecer una l√≠nea base.
        *   **Arquitectura:** Entrada -> Densa(16, ReLU, L2=0.1) -> BatchNormalization -> Dropout(0.5) -> Densa(1, Sigmoid).
        *   **Entrenamiento:** Optimizador Adam, p√©rdida `binary_crossentropy`, `EarlyStopping` (patience=10).
        *   **Evaluaci√≥n Inicial:** Matriz de confusi√≥n y Curva ROC-AUC (umbral de predicci√≥n 0.6).

4.  **Manejo del Desbalance de Clases con SMOTE:**
    *   Se aplic√≥ **SMOTE** (`sampling_strategy='auto'`) **√∫nicamente al conjunto de entrenamiento escalado** para generar muestras sint√©ticas de la clase minoritaria (fraude), equilibrando as√≠ las clases para el entrenamiento.

5.  **Reentrenamiento y Evaluaci√≥n del Modelo con Datos Balanceados:**
    *   Se **reentren√≥** un modelo con una arquitectura similar (ajustando la regularizaci√≥n L2 a 0.01 y `EarlyStopping` patience a 15) utilizando los datos de entrenamiento aumentados con SMOTE.
    *   Se evalu√≥ este nuevo modelo en el **conjunto de prueba original (no modificado por SMOTE)** para una evaluaci√≥n imparcial.
    *   Se gener√≥ el **Reporte de Clasificaci√≥n** (Precisi√≥n, Recall, F1-score) y una nueva **Matriz de Confusi√≥n** y **Curva ROC-AUC** (umbral de predicci√≥n 0.5).

## üîë T√©cnicas y Conceptos Clave Aplicados

*   **Redes Neuronales con Keras/TensorFlow:** Dise√±o e implementaci√≥n de arquitecturas de clasificaci√≥n.
*   **Clasificaci√≥n Binaria.**
*   **Preprocesamiento de Datos:** Escalado y divisi√≥n.
*   **Regularizaci√≥n:** L2 y Dropout para combatir el sobreajuste.
*   **Batch Normalization:** Para mejorar la convergencia.
*   **Early Stopping:** Para optimizar el entrenamiento.
*   **Manejo del Desbalance de Clases:**
    *   An√°lisis del impacto del desbalance.
    *   Aplicaci√≥n de **SMOTE** (Synthetic Minority Over-sampling Technique).
*   **M√©tricas de Evaluaci√≥n Robustas:**
    *   Matriz de Confusi√≥n.
    *   Curva ROC y √Årea Bajo la Curva (AUC).
    *   Precisi√≥n, Recall y F1-Score (especialmente para la clase minoritaria).

## üìà Resultados y Evaluaci√≥n

#### Modelo Inicial (Sin SMOTE, Umbral 0.6):
*   **AUC:** 0.9718. Un buen poder discriminatorio general.
*   La Matriz de Confusi√≥n inicial mostr√≥ una tendencia a clasificar bien la clase mayoritaria, con un n√∫mero limitado de fraudes detectados correctamente.

#### Modelo Reentrenado con SMOTE (Umbral 0.5):
*   **AUC:** 0.9651.
*   **Reporte de Clasificaci√≥n para la Clase Fraude (1):**
    *   **Precisi√≥n:** 0.1963
    *   **Recall (Sensibilidad):** 0.8947
    *   **F1-Score:** 0.3220

## ‚öñÔ∏è Discusi√≥n sobre el Impacto de SMOTE

*   **Mejora del Recall:** La aplicaci√≥n de SMOTE **aument√≥ significativamente el Recall** para la clase minoritaria (fraude) a **0.89**. Esto significa que el modelo es mucho mejor detectando los fraudes existentes.
*   **Disminuci√≥n de la Precisi√≥n:** Como es com√∫n con el sobremuestreo, la **Precisi√≥n para la clase fraude disminuy√≥**. Esto se debe a que al generar m√°s ejemplos de la clase minoritaria, el modelo puede volverse m√°s propenso a clasificar incorrectamente ejemplos de la clase mayoritaria como minoritarios (falsos positivos).
*   **Trade-off Precisi√≥n-Recall:** Existe un claro compromiso. En la detecci√≥n de fraudes, un alto Recall suele ser prioritario, pero esto debe equilibrarse con el coste de los falsos positivos.
*   **Ligera Disminuci√≥n del AUC:** El AUC baj√≥ ligeramente de 0.9718 a 0.9651. Esto puede suceder porque SMOTE, al generar puntos sint√©ticos, podr√≠a introducir algo de "ruido". Sin embargo, el AUC sigue siendo muy alto.

SMOTE ayud√≥ a que el modelo detectara mejor la clase minoritaria, aunque con un coste en la precisi√≥n.

## üíª Tecnolog√≠as Utilizadas

*   ![Python](https://img.shields.io/badge/Python-3.x-blue.svg?style=flat-square&logo=python)
*   ![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-orange.svg?style=flat-square&logo=tensorflow)
*   ![Keras](https://img.shields.io/badge/Keras-%23D00000.svg?style=flat-square&logo=Keras&logoColor=white)
*   ![Pandas](https://img.shields.io/badge/Pandas-%23150458.svg?style=flat-square&logo=pandas&logoColor=white)
*   ![NumPy](https://img.shields.io/badge/NumPy-%23013243.svg?style=flat-square&logo=numpy&logoColor=white)
*   ![Scikit-learn](https://img.shields.io/badge/scikit--learn-%23F7931E.svg?style=flat-square&logo=scikit-learn&logoColor=white)
*   ![Imbalanced-learn](https://img.shields.io/badge/Imbalanced--learn-brightgreen.svg?style=flat-square)
*   ![Matplotlib](https://img.shields.io/badge/Matplotlib-%23ffffff.svg?style=flat-square&logo=Matplotlib&logoColor=black)
*   ![Seaborn](https://img.shields.io/badge/Seaborn-%23023e8a.svg?style=flat-square&logo=seaborn&logoColor=white)
*   Jupyter Notebook / Google Colab

## ‚ú® Conclusi√≥n

Este proyecto demuestra la aplicaci√≥n de Deep Learning para la detecci√≥n de fraudes, con un enfoque espec√≠fico en el manejo del desbalance de clases mediante SMOTE. Se observa que SMOTE puede mejorar significativamente la detecci√≥n de la clase minoritaria (Recall), aunque introduce un trade-off con la Precisi√≥n. El modelo reentrenado con datos balanceados por SMOTE sigue mostrando un alto poder discriminatorio (AUC ~0.97), evidenciando la robustez del enfoque y la importancia de seleccionar m√©tricas adecuadas para problemas desbalanceados.
